{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Our recommendation is to use [Miniconda](https://docs.anaconda.com/miniconda/) to manage your `Python` environment.\n",
    "If you have not installed Miniconda or Anaconda yet, follow the installation instructions [here](https://docs.anaconda.com/miniconda/#quick-command-line-install).\n",
    "\n",
    "As soon as you have installed Miniconda, you can create a new environment with the name `deeplearning` by running\n",
    "```bash\n",
    "conda create -n \"deeplearning\" python=3.11.5\n",
    "```\n",
    "\n",
    "After creating the environment, use the following command to activate it:\n",
    "```bash\n",
    "conda activate deeplearning\n",
    "```\n",
    "\n",
    "If you open this Jupyter notebook in VSCode, select the Python interpreter in the `deeplearning` conda environment in the upper right corner.\n",
    "VSCode will then prompt you to install the `ipykernel` package, which you should install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "We will now install the latest [PyTorch](https://pytorch.org/) version. \n",
    "+ If you have an NVIDIA GPU, this will automatically install the CUDA 12.1 version. \n",
    "+ If you have a different CUDA version, please check the [official website](https://pytorch.org/) for the correct installation command. \n",
    "+ It's also fine if you only have a CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.4.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/twede/miniforge3/envs/deeplearning/lib/python3.11/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDEs\n",
    "\n",
    "Recommended:\n",
    "\n",
    "+ [Visual Studio Code](https://code.visualstudio.com/) (with the `Jupyter` and `Python` extensions)\n",
    "+ [Jetbrains PyCharm](https://www.jetbrains.com/pycharm/) (The student version is totally sufficient for this course, but you can also get the professional edition for free with your university email (https://www.jetbrains.com/shop/eform/students).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# PyTorch Introduction\n",
    "\n",
    "This tutorial is based on the excellent tutorial from the [PyTorch website](https://pytorch.org/tutorials/beginner/basics/intro.html), written by Suraj Subramanian, Seth Juarez, Cassie Breviu, Dmitry Soshnikov and Ari Bornstein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Tensors are essentially **multidimensional arrays**.\n",
    "+ Used in `PyTorch` to encode model inputs, outputs, and parameters.\n",
    "+ Similar to NumPyâ€™s `ndarrays` but can run on **GPUs and hardware accelerators**.\n",
    "+ Tensors and NumPy arrays can share the same memory, avoiding data copying.\n",
    "+ Optimized for **automatic differentiation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a tensor from a multidimensional Python array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1, 2], [3, 4], [5, 6]]\n",
    "\n",
    "x_torch = torch.tensor(x)\n",
    "x_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which is akin to how we create numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = np.array(x)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a torch tensor directly from a numpy array, which shares the same memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch_from_np = torch.from_numpy(x_np)\n",
    "x_torch_from_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also convert a tensor to a numpy array using the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor attributes: `dtype`, `shape`, and `device`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have a `dtype` attribute that specifies the data type of the elements in the tensor. \n",
    "\n",
    "Since the original list contains integers, the tensor is of type `torch.int64` (type inference).\n",
    "The default type is `torch.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we create a tensor from a list of *floats*, the tensor will be of type `torch.float32`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch = torch.tensor([[1., 2.], [3., 4.], [5., 6.]])\n",
    "x_torch.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explictly set the dtype when constructing a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float64)\n",
    "x_torch.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in `numpy`, each torch tensor has a `shape` attribute that describes the size of each dimension of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "\n",
      "Shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x_torch = torch.tensor([[1., 2.], [3., 4.], [5., 6.]])\n",
    "print(x_torch)\n",
    "print(f'\\nShape: {x_torch.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e., `x_torch` $\\in \\mathbb{R}^{3 \\times 2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `torch` tensors are created on the CPU. \n",
    "We can check which device the tensor is on using the `.device` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_torch.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a GPU, we can move it to the GPU using the `to` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_torch = x_torch.to(DEVICE)\n",
    "x_torch.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensors with default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other convenient ways to create tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(3, 2)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3, 2)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3683, -0.1100],\n",
       "        [-0.3104,  0.6630],\n",
       "        [ 0.1123, -1.2856]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_samples = torch.randn(3, 2)\n",
    "normal_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = torch.arange(6.)\n",
    "arange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already have a tensor and we want to create a new tensor with the same `shape`, `dtype`, and `device`, we can use the following methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones_like(x_torch)\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros_like(x_torch)\n",
    "normal_samples = torch.randn_like(x_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7.])\n",
      "\n",
      "Shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "arange = torch.arange(8.)\n",
    "print(arange)\n",
    "print(f'\\nShape: {arange.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.],\n",
       "        [4., 5.],\n",
       "        [6., 7.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = arange.reshape(4, 2)\n",
    "arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1.],\n",
       "         [2., 3.]],\n",
       "\n",
       "        [[4., 5.],\n",
       "         [6., 7.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arange = arange.reshape(2, 2, 2)\n",
    "arange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(16.).reshape(4, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing works the same way as in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([0., 1., 2., 3.])\n",
      "First column: tensor([ 0.,  4.,  8., 12.])\n",
      "Second column: tensor([ 1.,  5.,  9., 13.])\n",
      "Last column: tensor([ 3.,  7., 11., 15.])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First row: {tensor[0, :]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Second column: {tensor[:, 1]}\")\n",
    "print(f\"Last column: {tensor[:, -1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Broadcast operation](https://pytorch.org/docs/stable/notes/broadcasting.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5000,  2.5000,  3.5000,  4.5000],\n",
       "        [ 5.5000,  6.5000,  7.5000,  8.5000],\n",
       "        [ 9.5000, 10.5000, 11.5000, 12.5000],\n",
       "        [13.5000, 14.5000, 15.5000, 16.5000]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tensor + 1.5\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add two tensors of same shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5000,  3.5000,  5.5000,  7.5000],\n",
       "        [ 9.5000, 11.5000, 13.5000, 15.5000],\n",
       "        [17.5000, 19.5000, 21.5000, 23.5000],\n",
       "        [25.5000, 27.5000, 29.5000, 31.5000]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component-wise product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   2.5000,   7.0000,  13.5000],\n",
       "        [ 22.0000,  32.5000,  45.0000,  59.5000],\n",
       "        [ 76.0000,  94.5000, 115.0000, 137.5000],\n",
       "        [162.0000, 188.5000, 217.0000, 247.5000]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can *transpose* the tensor using the `T` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.]])\n",
      "\n",
      "\n",
      "tensor([[ 0.,  4.,  8., 12.],\n",
      "        [ 1.,  5.,  9., 13.],\n",
      "        [ 2.,  6., 10., 14.],\n",
      "        [ 3.,  7., 11., 15.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)\n",
    "print('\\n')\n",
    "print(tensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[224., 248., 272., 296.],\n",
       "        [248., 276., 304., 332.],\n",
       "        [272., 304., 336., 368.],\n",
       "        [296., 332., 368., 404.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.T @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 120.0\n",
      "Product: 0.0\n",
      "Max: 15.0\n",
      "Min: 0.0\n",
      "Mean: 7.5\n"
     ]
    }
   ],
   "source": [
    "print(f'Sum: {torch.sum(tensor)}')\n",
    "print(f'Product: {torch.prod(tensor)}')\n",
    "print(f'Max: {torch.max(tensor)}')\n",
    "print(f'Min: {torch.min(tensor)}')\n",
    "print(f'Mean: {torch.mean(tensor)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aggregate values over certain dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24., 28., 32., 36.])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_sums = torch.sum(tensor, dim=0)\n",
    "col_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{y} = (y_1, \\dots, y_n)^T$ and $\\hat{\\mathbf{y}} = (\\hat{y}_1, \\dots, \\hat{y}_n)^T$.\n",
    "The *mean squared error function* is given by\n",
    "$$\\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return torch.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance reasons, *avoid loops at all costs*. Instead, use the built-in functions that operate on the entire tensor at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do *not* do this:\n",
    "def loss_fn_slow_please_dont_do_this(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for y, y_hat in zip(y_true, y_pred):\n",
    "        loss += (y - y_hat) ** 2\n",
    "    \n",
    "    return loss / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dummy data. Note that we set `requires_grad=True` for `y_hat` because we will compute gradients with respect to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(302); np.random.seed(302)\n",
    "\n",
    "y_true = torch.randn(10)\n",
    "y_hat = torch.randn(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: tensor([ 1.2101,  0.9257, -0.6577, -1.6145,  0.7098, -1.2300, -1.1954, -0.1903,\n",
      "         0.2244, -1.3593])\n",
      "Predicted: tensor([-0.2696,  0.9912,  2.6123, -0.2423, -1.8687,  0.2160, -0.1764,  1.1408,\n",
      "        -0.4920,  1.2591], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(f'True: {y_true}')\n",
    "print(f'Predicted: {y_hat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test *automatic differentiation* with PyTorch.\n",
    "\n",
    "For example, let's compute $$ \\nabla_{\\hat{\\mathbf{y}}} \\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}})$$\n",
    "for our **particular values** of $\\mathbf{y}$ and $\\hat{\\mathbf{y}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3690, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(y_true, y_hat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access $ \\nabla_{\\hat{\\mathbf{y}}} \\mathcal{L}(\\mathbf{y}, \\hat{\\mathbf{y}})$, we can use the `grad` attribute of the tensor `y_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2959,  0.0131,  0.6540,  0.2744, -0.5157,  0.2892,  0.2038,  0.2662,\n",
       "        -0.1433,  0.5237])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
